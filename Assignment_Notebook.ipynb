{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import json\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "print (df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    processed_tokens = []\n",
    "    negation = False\n",
    "    for word in tokens:\n",
    "        if word in ['not', 'never']:\n",
    "            negation = True\n",
    "        elif word.isalpha() and word not in stop_words:\n",
    "            if negation:\n",
    "                word = 'not_' + word  \n",
    "                negation = False\n",
    "            word = lemmatizer.lemmatize(word)  \n",
    "            processed_tokens.append(word)\n",
    "        else:\n",
    "            negation = False\n",
    "    return ' '.join(processed_tokens)\n",
    "\n",
    "print('\\n\\nStarting Preprocessing')\n",
    "df['review'] = df['review'].apply(preprocess)\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "print('\\n\\nFinished Preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], random_state = 0, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "this cell is very computationally taxing due to it running 720 combinations 5 times each, totalling in 3600 fits\n",
    "if you need to run it to see if it works, i'd recommend deleting the n_jobs= -1 flag as it will use all resources on your computer, making it difficult to stop execution\n",
    "'''\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(min_df=5)),\n",
    "    ('lr', LogisticRegression(max_iter=1000, solver='saga'))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n",
    "    'tfidf__max_features': [5000, 10000, None],\n",
    "    'lr__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'lr__penalty': ['l2', 'l1', 'elasticnet', None], \n",
    "    'lr__l1_ratio': [0.2, 0.5, 0.8]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', verbose=2, n_jobs=-1, error_score='raise')\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print('Optimized Model Accuracy:' accuracy)\n",
    "print(classification_report(y_test, predictions))\n",
    "print('AUC score:', roc_auc_score(y_test, predictions))\n",
    "with open('bestparameters_LR-HP.json', 'w') as file:\n",
    "    json.dump(best_parameters, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(min_df=5, ngram_range=(1, 5))\n",
    "x_train_vectorised = vect.fit_transform(x_train)\n",
    "x_test_vectorised = vect.transform(x_test)\n",
    "\n",
    "models = {\n",
    "    'MultinomialNB': MultinomialNB(alpha=0.1),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'SVC': SVC(),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'GradientBoosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "def model_experiment(models, x_train, y_train, x_test, y_test):\n",
    "    for name, model in models.items():\n",
    "        model.fit(x_train, y_train)\n",
    "        predictions = model.predict(x_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        print(name, 'Accuracy:', accuracy)\n",
    "        print(classification_report(y_test, predictions))\n",
    "        print('AUC score:', roc_auc_score(y_test, predictions))\n",
    "        print('\\n')\n",
    "\n",
    "model_experiment(models, x_train_vectorised, y_train, x_test_vectorised, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(min_df=5, ngram_range=(1, 4))\n",
    "x_train_vectorised = vect.fit_transform(x_train)\n",
    "\n",
    "model = LogisticRegression(C=10, penalty='l2', max_iter=1000) \n",
    "\n",
    "model.fit(x_train_vectorised, y_train)\n",
    "x_test_vectorised = vect.transform(x_test)\n",
    "predictions = model.predict(x_test_vectorised)\n",
    "\n",
    "print('\\n\\n')\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print('Accuracy:', accuracy)\n",
    "print(classification_report(y_test, predictions))\n",
    "print('AUC score is: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predictions)\n",
    "# Plotting using Seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Purples', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(x_test_vectorised)[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, predictions, output_dict=True)\n",
    "sns.heatmap(pd.DataFrame(report).iloc[:-1, :].T, annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
